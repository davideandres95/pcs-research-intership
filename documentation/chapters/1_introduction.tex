%!TEX root = ../main.tex
\chapter{Introduction}\label{chap:introduction}

The constant demand for higher capacity digital links has motivated the development of communication schemes which approach closer and closer the analytical limit of the channel capacity. According to the definition of channel capacity, sending a single bit per time-frequency slot is inefficient. For this reason, higher-order modulations like \cgls{ask} or \cgls{qam} are used for better efficiency. Under these modulation schemes, the receiver handles more than two signal points per real dimension --- the set of spacial signal points is known as constellation. However, these schemes present a constant-width gap to the capacity limit. This is due to the use of both uniform and discrete probability distributions for the occurrence of the constellation points. While it is not possible to move away from the discrete distributions because of the digital nature of the communication, constellations with specific non-uniform distributions and optimized spatial locations can lead to further capacity improvements. 

Constellation shaping thus, is a technique which seeks to optimize the distribution of the transmit symbols. Furthermore, this optimization unfolds into the improvement of the constellation points' location, their occurrence probability or both simultaneously. The first is known as geometric shaping while the latter is known as probabilistic shaping. In both cases, the goal is to maximize the \cgls{mi} of the channel input X and output Y, which we denote with $I(X;Y)$, by optimizing the constellation. This optimization problem arises from the definition of channel capacity $C$:
\begin{align}
\label{eqn:capacity}
	C = \max_{p(X)} I(X;Y).
\end{align}

Currently, the optimal $p(x)$ has only been found for specific channels, such as the \cgls{awgn}, since knowledge of the channel distribution $p(y|x)$ is required. Still, solving (\ref{eqn:capacity}) can become mathematically intractable despite knowing $p(y|x)$.

Here is where the use of machine-learning is key for finding constellations which maximize $I(X;Y)$, without analytical knowledge of the channel or with very complex $p(y|x)$. As shown in \cite{O'Shea}, the complete communication system can be interpreted as an autoencoder. This approach tackles the physical layer by optimizing the end-to-end performance instead of the performance of the individual components. To achieve this, the loss function, against which the trainable parameters will be optimized, must be carefully selected. What is more, geometric shaping under the autoencoder framework has been already performed in \cite{O'Shea} and \cite{Jones}. Still, learning a probability distribution presents an additional challenge --- the sampling mechanism must be differentiable. On the contrary, if the sampling mechanism is not differentiable, the numerical approximations for computing the gradient of the trainable parameters become imprecise due to the change of statistics in the training set. \cite{Stark} and \cite{Aref} address this problem with different proposals. Their results show that joint probabilistic and geometric shaping outperform the PS-QAM scheme from \cite{Boecherer} and approach the limit to within 0.1 dB in the AWGN channel. Nonetheless, the existence of multiple and apparently different architectures invites for a comparative study. Consequently, in this work we implement and discuss the architectures proposed by \cite{Stark} and \cite{Aref}.

The rest of this document is organized as follows. Chapter 2, Preliminaries, presents the fundamentals of classical Probabilistic constellation systems as well as of autoencoder systems. Chapter 3, Contribution, presents a comparative study of two autoencoder architectures which can perform joint probabilistic and geometric constellation shaping and highlights their limitations. Chapter, Conclusions, 4 wraps-up this work.
