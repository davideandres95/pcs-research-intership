%!TEX root = ../main.tex
\chapter{Introduction}\label{chap:introduction}

The constant demand for higher capacity digital links has motivated the development of communication schemes which approach closer and closer the analytical limits of the channel capacity. This search for optimality has depicted a logical path. Sending a single bit per time-frequency slot is inefficient according to the definition of Channel capacity. Therefore, higher-order modulations like \cGls{ask} or \cGls{qam} were developed to improve the efficiency. Under these modulation schemes, the receiver handles more than two signal points per real dimension. The set of signal points is known as constellation. However, these schemes make use of uniform probability distributions for the occurrence of the constellation points leading to a constant-width gap to capacity. Once these schemes were adopted and additional capacity was required, research tackled the root cause of the constant gap, the usage of uniform distributions.

To overcome this gap constellation shaping techniques can be applied. Shaping a constellation means optimizing the distribution of the signal to be transmitted. Furthermore, this optimization unfolds into the improvement of the constellation points' location or their occurrence probability. The first is known as geometric shaping while the latter is known as probabilistic shaping. In both cases, the goal is to maximize the \cGls{mi} $I(X;Y)$ of the channel  input X and output Y by optimizing the constellation. This optimization problem arises from the definition of channel capacity $C$:
\begin{align}
\label{eqn:capacity}
	C = \max_{p(X)} I(X;Y)
\end{align}

Currently, the optimal $p(x)$ has only be found for specific channels such as the AWGN as knowledge of the channel distribution $p(y|x)$ is required. Still, solving \ref{eqn:capacity} can become intractable despite knowing $p(y|x)$.

Here is where deep-learning can be applied to find constellations which maximize $I(X;Y)$, without analytical knowledge of the channel. As shown in \cite{O’Shea}, the complete communication systems can be interpreted as an autoencoder. This approach tackles the physical layer by optimizing the end-to-end performance instead of the performance of the individual components by carefully choosing the loss function. Geometric shaping under the autoencoder framework has been already performed in \cite{O’Shea}, \cite{Jones}. Furthermore, geometric shaping and probabilistic shaping have been jointly implemented in \cite{Stark}, \cite{Aoudia} and \cite{Aref}. The results show that the joint application of probabilistic and geometric shaping outperform the PS-QAM scheme from \cite{Boecherer} and approach the limit to within 0.1 dB in the AWGN channel. Yet the existence of multiple and apparently different architectures is intriguing. Consequently, in this work we study the differences in the implementations proposed by \cite{Stark} and \cite{Aref}.

The rest of this document is organized as follows. Chapter 2, Preliminaries, presents the fundamentals of classical Probabilistic constellation systems as well as of autoencoder systems. Chapter 3, presents an implementation of both architectures with Pytorch \cite{PyTorch} and analyses their main differences. Chapter 4 wraps-up this work.
