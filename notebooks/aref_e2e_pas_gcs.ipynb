{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf98e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a65c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Receiver(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(1, M)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = self.lin1(y)\n",
    "        return y\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(1, M, bias=False)\n",
    "        nn.init.constant_(self.lin1.weight, 1 / M)\n",
    "        self.out = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, y):\n",
    "        return self.out(self.lin1(y))\n",
    "\n",
    "class Mapper(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(M, 1)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = self.lin1(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d61f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(prob, n):\n",
    "    samples = torch.empty(0)\n",
    "    for idx, p in enumerate(prob):\n",
    "        occurrences = torch.round(n * p).type(torch.LongTensor)\n",
    "        samples = torch.cat((samples, torch.ones(occurrences, dtype=torch.int64) * torch.tensor(idx)))\n",
    "    indexes = torch.randperm(samples.shape[0])\n",
    "    return samples[indexes]\n",
    "\n",
    "def gradient_correction_factor(app, idx, prob, M):\n",
    "    (nn,M)= app.shape\n",
    "    cf  = torch.zeros(M)\n",
    "    for j in range(M):\n",
    "        tmp = app[:, j]\n",
    "        cf[j] = torch.sum(torch.log(tmp[idx==j])) / (nn*prob[j]) # tmp[idx==j] selects the ll of those xy pairs which belong to the current symbol j\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN_channel(x, sigma2):\n",
    "    noise_t = np.sqrt(sigma2)*torch.randn(x.shape)\n",
    "    return x + noise_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "n = 10_000\n",
    "SNR_dB = 5\n",
    "SNR = 10**(SNR_dB/10)\n",
    "sigma2 = 1/SNR\n",
    "nepochs = 4000\n",
    "\n",
    "dec = Receiver(M)\n",
    "enc = Encoder(M)\n",
    "mapper = Mapper(M)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "alphabet = np.arange(-(M-1),M,2)\n",
    "# alphabet = np.array([-10, -6, -3, -1, 1, 3, 6, 10]) <-- Non-uniform alphabet\n",
    "alphabet = alphabet / np.sqrt(np.mean(alphabet**2))\n",
    "alphabet_t = torch.tensor(alphabet).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alphabet_t.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, M):\n",
    "    i_onehot = nn.functional.one_hot(torch.tensor(i), 8).float()\n",
    "    print(mapper(i_onehot))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc.lin1._parameters['weight'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb002a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "opt = optim.Adam( list(enc.parameters()) + list(dec.parameters()) + list(mapper.parameters()), lr=lr)\n",
    "# opt = optim.Adam( list(enc.parameters()) + list(dec.parameters()), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.arange(1,M+1).squeeze()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapper(nn.functional.one_hot(torch.arange(M),M).float()).squeeze().shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b631ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(nepochs):\n",
    "    # logits = enc(torch.tensor([1], dtype=torch.float))\n",
    "    probs = enc(torch.tensor([1], dtype=torch.float))\n",
    "    # probs =  nn.functional.softmax(logits, -1)\n",
    "    #probs.retain_grad()\n",
    "\n",
    "    # Sample indexes\n",
    "    indices = sampler(probs, n)\n",
    "    indices = indices.type(torch.LongTensor)\n",
    "\n",
    "    # Modulation\n",
    "    alphabet_t = mapper(nn.functional.one_hot(torch.arange(M),M).float()).squeeze()\n",
    "    norm_factor = torch.rsqrt(torch.sum(torch.pow(torch.abs(alphabet_t), 2) * probs))\n",
    "    alphabet_norm =  alphabet_t * norm_factor \n",
    "    onehot = nn.functional.one_hot(indices, M).float()\n",
    "    symbols = torch.matmul(onehot, torch.transpose(input=alphabet_norm.reshape(1,-1), dim0=0, dim1=1))\n",
    "    \n",
    "    # Channel\n",
    "    y = AWGN_channel(symbols, sigma2) \n",
    "\n",
    "    # Demodulator\n",
    "    ll = dec(y.reshape(-1,1).float())\n",
    "    app = nn.functional.softmax(ll, 1) #Q(X|Y)\n",
    "\n",
    "    # Loss\n",
    "    loss = -(torch.sum(-probs*torch.log(probs)) - loss_fn(ll, indices))# -(H(X) - CE(P,Q)), the gradient descent minimizes, therefore we minimize the opposite to maximize the MI in the end.\n",
    "    opt.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "    # correction factor\n",
    "    cf = - (gradient_correction_factor(app, indices, probs, M) - torch.log(probs)).detach()\n",
    "\n",
    "    # if j % 500 == 0:\n",
    "    #     print('missing factors: ', cf.detach().numpy())\n",
    "    #     print('current grad: ', probs.grad.detach().numpy())\n",
    "\n",
    "    probs.register_hook(lambda grad: grad + cf)\n",
    "\n",
    "    # probs.grad += cf.detach()\n",
    "    # enc.lin1._parameters['weight'].grad += cf.reshape(-1, 1).detach()\n",
    "\n",
    "    \n",
    "    opt.step()\n",
    "\n",
    "    # Printout and visualization\n",
    "    if j % 500 == 0:\n",
    "        print(f'epoch {j}: Loss = {loss.detach().numpy() / np.log(2) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc.lin1._parameters['weight']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(symbols.detach().numpy(), bins=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "pp = (probs.reshape(-1,1)*probs.reshape(1,-1)).reshape(-1,1).detach().numpy()\n",
    "alph = alphabet_norm.detach().numpy()\n",
    "a = []\n",
    "for c in np.flip(alph):\n",
    "    for d in alph:\n",
    "        a.append(d+1j*c)\n",
    "plt.scatter(np.real(a), np.imag(a), pp*2000)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53cf811",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN_channel_np(x, sigma2):\n",
    "    noise = np.sqrt(sigma2) * np.random.randn(x.size)\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGNdemapper(y, const, varN):\n",
    "    apps = np.exp(-np.abs(np.transpose([y])-const)**2/(2*varN))\n",
    "    return apps / np.transpose([np.sum(apps, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xesmd(apps, idx):\n",
    "    \"\"\"\n",
    "    Estimates symbolwise equivocation from reference symbols indices and a posteriori probabilities.\n",
    "    \"\"\"\n",
    "    eq = -np.log(np.take_along_axis(apps, idx[:, None], axis=1) / np.transpose([np.sum(apps, 1)]))\n",
    "    eq[eq==np.inf] = 1000\n",
    "    return np.mean(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100_000\n",
    "SNR_dBs = np.arange(5,22)\n",
    "M = 8\n",
    "alphabet = np.arange(-7,8,2)\n",
    "alphabet = alphabet / np.sqrt(np.mean(alphabet**2))\n",
    "indices = np.random.choice(np.arange(M), n)\n",
    "symbols = alphabet[indices]\n",
    "\n",
    "mi_64 = []\n",
    "for snrdB in SNR_dBs:\n",
    "    sigma2 = 1/(10**(snrdB/10))\n",
    "    sigma2 = sigma2 \n",
    "    y = AWGN_channel_np(symbols, sigma2)\n",
    "    apps = AWGNdemapper(y, alphabet, sigma2)\n",
    "    xe = xesmd(apps, indices)\n",
    "    mi_64.append(2*(3 - (xe) / np.log(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print((-2*loss.detach()/np.log(2)).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.plot(SNR_dBs, mi_64, label = '64QAM')\n",
    "plt.plot(SNR_dBs, np.log2(1+10**(SNR_dBs/10)), color='black', label='Capacity')\n",
    "\n",
    "plt.plot(SNR_dB, -2*loss.detach()/np.log(2), color='red', marker='o', markersize=3)\n",
    "xy = (12, (-2*loss.detach()/np.log(2)).detach().numpy())\n",
    "plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SNR_dBs = np.arange(0,20)\n",
    "plt.plot(SNR_dBs, np.log2(1+10**(SNR_dBs/10)), color='C0', label='$C(P/\\sigma^2)$')\n",
    "plt.plot(SNR_dBs, np.log2(1+10**(SNR_dBs/10)) - 0.5*np.log2((np.pi*np.e)/6) , linestyle='dashed', color='C1', label='$C(P/\\sigma^2) - \\dfrac{1}{2}\\log_2\\dfrac{\\pi e}{6}$')\n",
    "plt.grid()\n",
    "plt.ylabel('bits per channel use')\n",
    "plt.xlabel('SNR in dB')\n",
    "plt.xlim([0, 20])\n",
    "plt.ylim([0, 5])\n",
    "# plt.title('AWGN channel capacity gap')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
